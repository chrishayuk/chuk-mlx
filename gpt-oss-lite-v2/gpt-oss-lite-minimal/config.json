{
  "model_type": "gpt_oss_lite_minimal",
  "architectures": [
    "GPTOSSLiteForCausalLM"
  ],
  "hidden_size": 2880,
  "intermediate_size": 2880,
  "num_hidden_layers": 24,
  "num_attention_heads": 64,
  "num_key_value_heads": 8,
  "vocab_size": 201088,
  "num_local_experts": 4,
  "num_experts_per_tok": 4,
  "rope_scaling": {
    "type": "yarn",
    "factor": 10.0,
    "original_max_position_embeddings": 16384
  },
  "hot_experts_by_layer": {
    "0": [
      17,
      19,
      25,
      31
    ],
    "1": [
      6,
      14,
      22,
      26
    ],
    "2": [
      20,
      23,
      26,
      27
    ],
    "3": [
      1,
      6,
      14,
      21
    ],
    "4": [
      6,
      19,
      23,
      27
    ],
    "5": [
      3,
      11,
      24,
      25
    ],
    "6": [
      2,
      5,
      15,
      21
    ],
    "7": [
      0,
      5,
      19,
      23
    ],
    "8": [
      8,
      9,
      17,
      21
    ],
    "9": [
      15,
      16,
      19,
      31
    ],
    "10": [
      6,
      7,
      10,
      28
    ],
    "11": [
      5,
      18,
      26,
      30
    ],
    "12": [
      9,
      15,
      21,
      23
    ],
    "13": [
      4,
      9,
      21,
      25
    ],
    "14": [
      0,
      6,
      16,
      29
    ],
    "15": [
      7,
      13,
      17,
      29
    ],
    "16": [
      4,
      13,
      14,
      31
    ],
    "17": [
      2,
      5,
      21,
      22
    ],
    "18": [
      1,
      7,
      18,
      25
    ],
    "19": [
      0,
      4,
      11,
      17
    ],
    "20": [
      8,
      12,
      19,
      22
    ],
    "21": [
      10,
      17,
      23,
      28
    ],
    "22": [
      5,
      13,
      26,
      27
    ],
    "23": [
      8,
      14,
      16,
      31
    ]
  },
  "source_model": "openai/gpt-oss-20b",
  "total_experts": 96,
  "original_experts": 768,
  "reduction_percent": "87.5%"
}