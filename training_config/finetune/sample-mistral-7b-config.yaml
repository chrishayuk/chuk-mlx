# Fine-tuning 

model:
  # model name
  name: "mistralai/Mistral-7B-Instruct-v0.2"

# optimizer settings
optimizer:
  name: AdamW
  initial_lr: 2e-5
  lr_schedule:
    type: cosine_decay
    warmup_steps: 10
  betas: [0.9, 0.95]
  eps: 1e-5
  weight_decay: 0.1

# checkpointing
checkpoint:
  frequency_epochs: 10  # Checkpoint every epochs
  frequency_iterations: 500  # Checkpoint every n iterations
  output_dir: './output/sample/checkpoints'

# training
training:
  num_epochs: 50
  total_iterations: 2000
  loss_function: models.chuk_loss_function.chukloss

# batches
batch:
  output_dir: './output/sample/batches'
  file_prefix: 'sample'