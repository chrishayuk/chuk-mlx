# phase 1 - pretraining

# optimizer settings
optimizer:
  name: AdamW
  initial_lr: 3e-4
  lr_schedule:
    type: cosine_decay
    minimum: 3e-5
    warmup_steps: 2000
  betas: [0.9, 0.95]
  eps: 1e-5
  weight_decay: 0.1